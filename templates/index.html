<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Emotion Recognition Demo</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            background-color: white;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 0 10px rgba(0,0,0,0.1);
        }
        video {
            width: 100%;
            max-width: 640px;
            border-radius: 10px;
        }
        button {
            background-color: #4CAF50;
            border: none;
            color: white;
            padding: 15px 32px;
            text-align: center;
            text-decoration: none;
            display: inline-block;
            font-size: 16px;
            margin: 10px 2px;
            cursor: pointer;
            border-radius: 5px;
        }
        button:hover {
            background-color: #45a049;
        }
        button:disabled {
            background-color: #cccccc;
            cursor: not-allowed;
        }
        #results {
            margin-top: 20px;
            padding: 10px;
            background-color: #e7f3ff;
            border-radius: 5px;
            display: none;
        }
        .emotion-result {
            font-size: 18px;
            margin: 5px 0;
        }
        .error {
            color: red;
            background-color: #ffe6e6;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Emotion Recognition Demo</h1>
        <p>Click "Start Recording" to record 15 seconds of video and audio for emotion analysis.</p>

        <video id="video" autoplay muted></video>
        <br><br>
        <button id="recordBtn">Start Recording</button>
        <div id="status"></div>

        <div id="results"></div>
        
        <div id="charts" style="display: none;">
            <h3>Temporal Emotion Analysis</h3>
            <canvas id="audioChart" width="400" height="200"></canvas>
            <canvas id="videoChart" width="400" height="200"></canvas>
        </div>
    </div>

    <script>
        let mediaRecorderVideo;
        let mediaRecorderAudio;
        let recordedVideoChunks = [];
        let recordedAudioChunks = [];
        let videoStream;
        let audioStream;
        let videoBlob;
        let audioBlob;

        const video = document.getElementById('video');
        const recordBtn = document.getElementById('recordBtn');
        const status = document.getElementById('status');
        const results = document.getElementById('results');

        // Get user media
        async function getMedia() {
            try {
                videoStream = await navigator.mediaDevices.getUserMedia({ video: true });
                audioStream = await navigator.mediaDevices.getUserMedia({ audio: true });

                video.srcObject = videoStream;

                // Video recorder
                mediaRecorderVideo = new MediaRecorder(videoStream, {
                    mimeType: 'video/webm'
                });
                mediaRecorderVideo.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        recordedVideoChunks.push(event.data);
                    }
                };
                mediaRecorderVideo.onstop = () => {
                    videoBlob = new Blob(recordedVideoChunks, { type: 'video/webm' });
                    recordedVideoChunks = [];
                    checkAndSend();
                };

                // Audio recorder
                mediaRecorderAudio = new MediaRecorder(audioStream, {
                    mimeType: 'audio/webm'
                });
                mediaRecorderAudio.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        recordedAudioChunks.push(event.data);
                    }
                };
                mediaRecorderAudio.onstop = () => {
                    audioBlob = new Blob(recordedAudioChunks, { type: 'audio/webm' });
                    recordedAudioChunks = [];
                    checkAndSend();
                };

                recordBtn.disabled = false;
                status.textContent = 'Ready to record. Click "Start Recording".';

            } catch (error) {
                console.error('Error accessing media devices:', error);
                status.textContent = 'Error: Could not access camera or microphone.';
            }
        }

        function checkAndSend() {
            if (videoBlob && audioBlob) {
                sendToServer(videoBlob, audioBlob);
                videoBlob = null;
                audioBlob = null;
            }
        }

        // Start recording
        recordBtn.onclick = () => {
            if (mediaRecorderVideo.state === 'recording') {
                mediaRecorderVideo.stop();
                mediaRecorderAudio.stop();
                recordBtn.textContent = 'Processing...';
                recordBtn.disabled = true;
                status.textContent = 'Recording stopped. Processing...';
            } else {
                recordedVideoChunks = [];
                recordedAudioChunks = [];
                mediaRecorderVideo.start();
                mediaRecorderAudio.start();
                recordBtn.textContent = 'Stop Recording';
                status.textContent = 'Recording... (15 seconds)';

                // Auto-stop after 15 seconds
                setTimeout(() => {
                    if (mediaRecorderVideo.state === 'recording') {
                        mediaRecorderVideo.stop();
                        mediaRecorderAudio.stop();
                        recordBtn.textContent = 'Processing...';
                        recordBtn.disabled = true;
                        status.textContent = 'Recording stopped. Processing...';
                    }
                }, 15000);
            }
        };

        // Send recorded data to server
        async function sendToServer(videoBlob, audioBlob) {
            const formData = new FormData();
            formData.append('video', videoBlob, 'recording.webm');
            formData.append('audio', audioBlob, 'recording_audio.webm');

            try {
                const response = await fetch('/process', {
                    method: 'POST',
                    body: formData
                });

                const data = await response.json();

                if (data.error) {
                    results.innerHTML = `<div class="error">Error: ${data.error}</div>`;
                } else {
                    results.innerHTML = `
                        <h3>Emotion Recognition Results:</h3>
                        <div class="emotion-result">Audio Emotion: ${data.audio_emotion}</div>
                        <div class="emotion-result">Video Emotion: ${data.video_emotion}</div>
                        <div class="emotion-result"><strong>Fused Emotion: ${data.fused_emotion}</strong></div>
                        <div class="emotion-result"><em>Reasoning: ${data.reasoning}</em></div>
                        <h4>AI-Generated Content:</h4>
                        <div class="emotion-result"><strong>Short Story:</strong> ${data.story}</div>
                        <div class="emotion-result"><strong>Quote:</strong> ${data.quote}</div>
                        <div class="emotion-result"><strong>YouTube Video:</strong> ${data.video}</div>
                        <div class="emotion-result"><strong>Songs:</strong> ${data.songs.join(', ')}</div>
                    `;
                    document.getElementById('charts').style.display = 'block';
                    createCharts(data);
                }

                results.style.display = 'block';
                recordBtn.textContent = 'Start Recording';
                recordBtn.disabled = false;
                status.textContent = 'Ready to record again.';

            } catch (error) {
                console.error('Error sending data:', error);
                results.innerHTML = '<div class="error">Error processing recording.</div>';
                results.style.display = 'block';
                recordBtn.textContent = 'Start Recording';
                recordBtn.disabled = false;
            }
        }

        function createCharts(data) {
            const emotions = ['neutral', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised'];
            const colors = ['blue', 'green', 'gray', 'red', 'orange', 'purple', 'yellow'];

            // Audio chart
            const audioCtx = document.getElementById('audioChart').getContext('2d');
            const audioData = emotions.map((emotion, idx) => ({
                label: emotion,
                data: data.audio_probs_temporal.map(probs => probs[idx]),
                borderColor: colors[idx],
                fill: false
            }));

            new Chart(audioCtx, {
                type: 'line',
                data: {
                    labels: data.time_points,
                    datasets: audioData
                },
                options: {
                    title: { display: true, text: 'Audio Emotion Probabilities Over Time' },
                    scales: { y: { beginAtZero: true, max: 1 } }
                }
            });

            // Video chart
            const videoCtx = document.getElementById('videoChart').getContext('2d');
            const videoData = emotions.map((emotion, idx) => ({
                label: emotion,
                data: data.video_probs_temporal.map(probs => probs[idx]),
                borderColor: colors[idx],
                fill: false
            }));

            new Chart(videoCtx, {
                type: 'line',
                data: {
                    labels: data.time_points,
                    datasets: videoData
                },
                options: {
                    title: { display: true, text: 'Video Emotion Probabilities Over Time' },
                    scales: { y: { beginAtZero: true, max: 1 } }
                }
            });
        }

        // Initialize
        getMedia();
    </script>
</body>
</html>